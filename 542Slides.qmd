---
title: "Customer Term Deposit Predictor"
author: "Meagan Gardner, Elshaday Yoseph, Shell Ou, Henry Ha"
format: revealjs
slide-number: true

---

## Land Acknowledgement

*With gratitude, we would like to acknowledge we are located on the traditional, unceded, ancestral territories of the xʷməθkʷəy̓əm (Musqueam), Sḵwx̱wú7mesh (Squamish), and səlil̓wətaɁɬ (Tsleil-Waututh) First Nations, whose historical relationships with the land continue to this day.*

---

## Presentation Overview
- **Meagan:** Background and research question
- **Elshaday:** Exploratory Data Analysis
- **Shell:** Logistic Regression Model
- **Henry:** Results and conclusion

---

## Canada's Investment Landscape
- 79% of Canadians recognize the importance of investing
- Only 48% actually invest annually
- Over half of those that don't invest state a fear of losing money
- **The Opportunity:** Low-risk investment options!
<center>
  ![](img/money-stress.png){ width=30% }
</center>

---

## What is a Term Deposit?
- A low-risk, stead way to grow your savings
- Money is locked in for a set duration, at a fixed interest rate
- At the end of term, the initial investment is returned plus interest earned
<center>
  ![](img/TermDeposit.png){ width=70% }
</center>
---

## Our Research Goal

**We aim to determine whether a machine learning model can predict if a customer will agree to open a term deposit**

-  This will lead to:
    - More targeted calling campaigns
    - Cost effectiveness
    - Improved customer relationships.

---

## The Dataset

- Dataset obtained from UCI Machine Learning Repository
- Each row represents a bank client
- 17 features capturing client characteristics:
    - Age, marital status, education level, past interactions, days since last contact
- Binary target column

# Exploratory Data Analysis

---

## Target Variable Distribution
::: {.columns}

::: {.column width="50%"}
- 88.3% are non-subscribers.
- 11.7% are subscribers.
- we need to focus on precision and recall, not just accuracy
:::

::: {.column width="50%"}
![](img/target_variable_distribution.png)
:::

:::
---

## Balance Distribution by Subscription Status
::: {.columns}

::: {.column width="50%"}
- Subscribers generally have higher balances compared to non-subscribers.
- There are significant outliers for both groups.
- Balance could be a strong predictor for subscription.
:::

::: {.column width="50%"}
![](img/balance_distribution.png){fig-align="center" width="100%"}
:::

:::

---

## Feature Densities by Class
::: {.columns}

::: {.column width="50%"}
- Age: Subscribers are concentrated in middle-aged groups.
- Balance: Subscribers tend to have higher balances.
- Campaign: Fewer contact attempts are common for most clients.
:::

::: {.column width="50%"}
![](img/age_distribution_density.png){fig-align="center" width="100%"}
:::

:::
---

## Correlation Heatmap
::: {.columns}

::: {.column width="50%"}
- Most features exhibit weak correlations.
- Moderate correlation observed between:
    - pdays (days since last contact) and previous (number of prior contacts).
:::

::: {.column width="50%"}
![](img/feature_densities_by_class.png){fig-align="center" width="100%"}
:::

:::
---

## Key Insights
- Dataset Imbalance:
    - Requires class balancing to improve predictions.
- Feature Selection:
    - Balance and contact-related features are likely key predictors.
- Preprocessing:
    - Addressed missing values and removed irrelevant features.

# The Model

---

## Logistic Regression Model Overview

- **Why Logistic Regression?**
  - Simple 
  - Interpretable 

- **Key Features Used in the Model:**
  - **Balance**
  - **Campaign and Previous Contact**
  - **Contact Method**

---

## Handling Dataset Imbalance

- **Challenge**:
  - The dataset is highly imbalanced, 11.7% subscribers.
  - The model would overpredict non-subscribers.

- **Solution**:
  - Applied class balancing techniques:
    - Weight adjustments to penalize misclassification of subscribers.

---

## Model Training Process

1. **Data Preprocessing**:
   - Standardized numerical features (e.g., balance, age).
   - One-hot encoded categorical variables (e.g., job, education, contact).

2. **Logistic Regression**:
   - Binary classification model with sigmoid activation.
   - Outputs probabilities for subscription likelihood.


---

## Model Evaluation Metrics

- **Key Metrics Used**:
  - **Precision**: Focus on positive predictions (subscribers).
  - **Recall**: Measure of sensitivity for subscriber identification.
  - **AUC-ROC**: Overall performance across thresholds.

- **Why These Metrics?**
  - Precision and recall balance is critical for imbalanced datasets.
  - AUC-ROC provides a broader perspective on model performance.


# Results and Discussion

## Confusion Matrix

::: {.columns}

::: {.column width="50%"}
- Successfully filters out 71.3% of non-subscribers
- Good recall for subscribers (0.65)
- Low precision for subscribers (0.24).
- 3 times better than dummy 
:::

::: {.column width="50%"}
![](img/Confusion_Matrix.png){fig-align="center" width="100%"}
:::

:::

---

## Precision-Recall Curve
::: {.columns}

::: {.column width="50%"}
- Precision-recall trade-off based on decision threshold
- Impact of threshold adjustments on precision and recall metrics
- Average precision (AP) score is 0.33

:::

::: {.column width="50%"}
![](img/PR_curve.png){fig-align="center" width="100%"}
:::

:::

---

## ROC Curve
::: {.columns}

::: {.column width="50%"}
- AUC score of 0.75 suggests moderate predictive power.
- Useful for assessing model performance across thresholds.


:::

::: {.column width="50%"}
![](img/ROC_curve.png){fig-align="center" width="100%"}
:::

:::

---

## Limitations

::: {.columns}

::: {.column width="50%"}
- Dataset Imbalance
- Model Scope
- Feature Limitations
- Parameter Optimization

:::

::: {.column width="50%"}
![](img/lim.png){fig-align="center" width="100%"}
:::

:::

---

## Future Research Directions

::: {.columns}

::: {.column width="50%"}
1) Advanced Models
2) Additional Features
3) Economic Context
4) Oversampling Techniques
5) Optimal Parameter Tuning

:::

::: {.column width="50%"}
![](img/dir.png){fig-align="center" width="100%"}
:::

:::

## Conclusion

1) Impactful Insights: Identified key predictors.
2) Model Effectiveness: Demonstrated improvements over the dummy model.
3) Room for Improvement: Explained current limitations.
4) Future Enhancements: Mentioned a few improvements.
5) Practical Benefits: Optimized stategy has many benefits.


# Questions?

---